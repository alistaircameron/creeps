{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creeps. Reading a .bib file, matching by name, and returning a message.\n",
    "\n",
    "\n",
    "TODO\n",
    "\n",
    "- the csv module will likely run on overleaf just fine: https://docs.python.org/3/library/csv.html\n",
    "\n",
    "- create an environment for this project (BUT, we will try to call as few packages as possible).\n",
    "\n",
    "- if someone's name is a pain in the arse, (i.e. not made with the characters a-z), what the heck do i do?\n",
    "\n",
    "- find bib files that aren't generated by google scholar\n",
    "\n",
    "- some author entries have double curly braces, i'm sure i'm stuffing them up: author={{World Food Summit}},\n",
    "\n",
    "\n",
    "- just take names as given, don't edit. match. later on, can think about adding different options using TheFuzz and leivenstein distance stuff as well as dropping middle names and run:\n",
    "    - if it's got a \".\" kill the \".\"\n",
    "    - if it's got a word that is only 1 leter long, kill the word (that's gonna be an initial).\n",
    "    - kill \" Jr \"; \" Sr \" .... any others like that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Take the database of offenders and return names. Turn this into a csv, just rip out what i want, so that later, i can do this without pandas.\n",
    "\n",
    "df = pd.read_csv('asmd_incidents.csv', usecols=['Person', 'Institution', 'Original Link(s)']) # Just load the usable columns.\n",
    "df = df[(df.Person != 'NAME UNKNOWN') & ~df.Person.isna()]\n",
    "\n",
    "df['Person'] = df['Person'].astype(str).str.lower()\n",
    "# df['Person'] = df['Person'].str.replace(',',\"\") # This is necessary for later on. There's one bloke who is so and so Junior, and has a comma in his name.\n",
    "offenders = [offender for offender in list(df.Person)] # Offenders isn't used, so remove.\n",
    "\n",
    "df.columns = ['person', 'institution', 'source']\n",
    "df.to_csv('asmd.csv', index = False, sep = \"\\t\") # Some of the names have a comma, and even some of URLs, so this helps for the string splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the csv, using vanilla python, return a dictionary with names and links.\n",
    "offenders, institutions, sources = [], [], []\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open('asmd.csv', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        off, inst, src = line.split('\\t')\n",
    "#        off, inst, src = line.rstrip(\"\\n\").split('\\t')\n",
    "        offenders.append(off.strip())\n",
    "        institutions.append(inst.strip())\n",
    "        sources.append(src.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples.bib\n"
     ]
    }
   ],
   "source": [
    "# Take the csv, using vanilla python, return a dictionary with names and links.\n",
    "offenders, institutions, sources = [], [], []\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "# with open('asmd.csv', 'r') as file:\n",
    "#     for line in file.readlines():\n",
    "#         offenders.append(line.strip().split(',')[0])\n",
    "#         institutions.append(line.strip().split(',')[1])\n",
    "#         sources.append(line.strip().split(',')[2])\n",
    "\n",
    "\n",
    "with open('asmd.csv', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        off, inst, src = line.split('\\t')\n",
    "#        off, inst, src = line.rstrip(\"\\n\").split('\\t')\n",
    "        offenders.append(off.strip())\n",
    "        institutions.append(inst.strip())\n",
    "        sources.append(src.strip())\n",
    "\n",
    "# TODO - make it more memory efficient, and do this with the csv module, rather than saving first as lists.\n",
    "# Create a dictionary of the above.\n",
    "offd = dict(zip(offenders,zip(institutions, sources)))\n",
    "\n",
    "\n",
    "# Take a .bib file, return the authors.\n",
    "bibfile = \"examples\"\n",
    "if not bibfile.endswith(\".bib\"):\n",
    "    bibfile = bibfile + \".bib\"\n",
    "\n",
    "print(bibfile)\n",
    "\n",
    "# TODO -- choose one way of doing this, probably the first way!\n",
    "with open(bibfile) as refs:\n",
    "    keys = [line.strip().split(\"{\")[1].rstrip(',').strip().lower() for line in refs if line.strip().startswith(\"@\")]\n",
    "\n",
    "with open(bibfile) as refs:\n",
    "    authors = [line.strip().split(\"{\")[1].split(\"}\")[0].split(\" and \") for line in refs if line.strip().split(\"=\")[0].lower().__contains__(\"author\")]\n",
    "\n",
    "# keys, authors = [], []\n",
    "# with open('references.bib') as refs:\n",
    "#     for line in refs.readlines():\n",
    "#         if line.strip().startswith(\"@\"):\n",
    "#             keys.append(line.strip().split(\"{\")[1].rstrip(',').strip())\n",
    "\n",
    "#         elif line.strip().split(\"=\")[0].lower().__contains__(\"author\"):\n",
    "#             authors.append(line.strip().split(\"{\")[1].split(\"}\")[0].split(\" and \"))\n",
    "\n",
    "\n",
    "\n",
    "# If the name is of the form: \"last_name, first_name (middle_names)\", flip it around and remove the comma, so it is of the form: \"first_name (middle names) last_name\"\n",
    "for i in range(len(authors)):\n",
    "    authors[i] = [x.split(\",\")[1].strip().lower() + \" \" + x.split(\",\")[0].strip().lower() if x.__contains__(\",\") else x for x in authors[i]]\n",
    "\n",
    "names = [item.lower() for sublist in authors for item in sublist]\n",
    "# for i in range(len(keys)):\n",
    "#    print(f'{keys[i]}: {authors[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dittmann1976strindberg'], ['naqvi1995power', 'batra1987urban']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works nicely only for exact name matching.\n",
    "warnings = set([name for name in names if name in offenders])\n",
    "\n",
    "\n",
    "# Turn to dictionary\n",
    "bibd = dict(zip(keys, authors))\n",
    "\n",
    "\n",
    "# Return the relevant bibliography identifiers for each offender.\n",
    "\n",
    "article_ids, institutions, sources = [], [], [] # this overwrites previous stuff. ugly, i know.\n",
    "for w in warnings:\n",
    "    art_id = []\n",
    "    for k, v in bibd.items():\n",
    "        if w in v:\n",
    "            art_id.append(k)\n",
    "\n",
    "    article_ids.append(art_id)\n",
    "\n",
    "    for k, v in offd.items():\n",
    "        if k == w:\n",
    "            institutions.append(offd.get(w)[0])\n",
    "            sources.append(offd.get(w)[1])\n",
    "\n",
    "article_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usg.edu/assets/regents/documents/board_meetings/aug99min.pdf\n"
     ]
    }
   ],
   "source": [
    "for j in sources[i].split(\";\"):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- reidar dittmann [St. Olaf College; ['dittmann1976strindberg']] is matched to the database of offenders. For details, see \n",
      "\\href{https://www.insidehighered.com/news/2017/03/15/how-st-olaf-scrubbed-building-name-revered-professor-accused-sexual-misconduct}{here}\n",
      ".\n",
      "\n",
      "\n",
      "-- nadeem naqvi [University of Georgia; ['naqvi1995power', 'batra1987urban']] is matched to the database of offenders. For details, see \n",
      "\\href{https://www.usg.edu/assets/regents/documents/board_meetings/aug99min.pdf}{here}\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO turn the sources into a clickable link?\n",
    "\n",
    "for i in range(len(warnings)):\n",
    "    message = f\"-- {list(warnings)[i]} [{institutions[i]}; {article_ids[i]}] is matched to the database of offenders. For details, see \" \n",
    "    print(message)\n",
    "\n",
    "    # Now, cycle through, print it if it's the final source in the list with a full stop after, otherwise print with a comma.\n",
    "    for k, j in enumerate(sources[i].split(\";\")):\n",
    "        if k != len(sources[i].split(\";\")) -1:\n",
    "            details = f\"\\href{{{j}}}{{here}}, \"\n",
    "            print(details)\n",
    "        else:\n",
    "            details = f\"\\href{{{j}}}{{here}}.\"\n",
    "            print(details)\n",
    "\n",
    "\n",
    "    print('\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron@pm.me/creeps/code/creeps.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadlines():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         offenders\u001b[39m.\u001b[39mappend(line\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         institutions\u001b[39m.\u001b[39mappend(line\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         sources\u001b[39m.\u001b[39mappend(line\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m2\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# TODO - make it more memory efficient, and do this with the csv module, rather than saving first as lists.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alistair/Library/CloudStorage/ProtonDrive-alistair.cameron%40pm.me/creeps/code/creeps.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Create a dictionary of the above.\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Cleanish for overleaf.\n",
    "\n",
    "\n",
    "# Take the csv, using vanilla python, return a dictionary with names and links.\n",
    "offenders, institutions, sources = [], [], []\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open('asmd.csv', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        offenders.append(line.strip().split(',')[0])\n",
    "        institutions.append(line.strip().split(',')[1])\n",
    "        sources.append(line.strip().split(',')[2])\n",
    "\n",
    "# TODO - make it more memory efficient, and do this with the csv module, rather than saving first as lists.\n",
    "# Create a dictionary of the above.\n",
    "offd = dict(zip(offenders,zip(institutions, sources)))\n",
    "\n",
    "\n",
    "# Take a .bib file, return the authors.\n",
    "bibfile = \"examples\"\n",
    "if not bibfile.endswith(\".bib\"):\n",
    "    bibfile = bibfile + \".bib\"\n",
    "\n",
    "# TODO -- choose one way of doing this, probably the first way!\n",
    "with open(bibfile) as refs:\n",
    "    keys = [line.strip().split(\"{\")[1].rstrip(',').strip().lower() for line in refs if line.strip().startswith(\"@\")]\n",
    "\n",
    "with open(bibfile) as refs:\n",
    "    authors = [line.strip().split(\"{\")[1].split(\"}\")[0].split(\" and \") for line in refs if line.strip().split(\"=\")[0].lower().__contains__(\"author\")]\n",
    "\n",
    "\n",
    "# If the name is of the form: \"last_name, first_name (middle_names)\", flip it around and remove the comma, so it is of the form: \"first_name (middle names) last_name\"\n",
    "for i in range(len(authors)):\n",
    "    authors[i] = [x.split(\",\")[1].strip().lower() + \" \" + x.split(\",\")[0].strip().lower() if x.__contains__(\",\") else x for x in authors[i]]\n",
    "\n",
    "names = [item.lower() for sublist in authors for item in sublist]\n",
    "\n",
    "\n",
    "# This works nicely only for exact name matching.\n",
    "warnings = set([name for name in names if name in offenders])\n",
    "\n",
    "\n",
    "# Turn to dictionary\n",
    "bibd = dict(zip(keys, authors))\n",
    "\n",
    "\n",
    "# Return the relevant bibliography identifiers for each offender.\n",
    "article_ids, institutions, sources = [], [], [] # this overwrites previous stuff. ugly, i know.\n",
    "for w in warnings:\n",
    "    art_id = []\n",
    "    for k, v in bibd.items():\n",
    "        if w in v:\n",
    "            art_id.append(k)\n",
    "\n",
    "    article_ids.append(art_id)\n",
    "\n",
    "    for k, v in offd.items():\n",
    "        if k == w:\n",
    "            institutions.append(offd.get(w)[0])\n",
    "            sources.append(offd.get(w)[1])\n",
    "\n",
    "\n",
    "# # TODO turn the sources into a clickable link?\n",
    "# for i in range(len(warnings)):\n",
    "#     message = f\"{list(warnings)[i]} has been found in the database of offenders. They're authors in {article_ids[i]} and the database has them working at {institutions[i]}. For further details, see {sources[i]}.\"\n",
    "#     print(message)\n",
    "\n",
    "\n",
    "for i in range(len(warnings)):\n",
    "    message = f\"-- {list(warnings)[i]} [{institutions[i]}; {article_ids[i]}] is matched to the database of offenders. For details, see \" \n",
    "    print(message)\n",
    "    for j, k in enumerate(sources[i].split(\";\")):\n",
    "        details = f\"\\href{{{j}}}{{here}}\"\n",
    "        print(details)\n",
    "        if j != len(sources[i].split(\";\")) -1:\n",
    "            print(\", \")\n",
    "        else:\n",
    "            print(\".\")\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sources[i].split(\";\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
